{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929de01-30d1-4216-a1a5-4a72da73ba8e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Created by Anil Burak Karadede (https://www.linkedin.com/in/anilburakkaradede/)\n",
    "pip install google-ads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264183c",
   "metadata": {},
   "source": [
    "# Google Ads API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0582d736-01bd-43c4-b1c8-450a3f027b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.ads.googleads.client import GoogleAdsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad12231-8316-4016-b732-7c2bbd01f101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "googleads_client = GoogleAdsClient.load_from_storage(\"google-ads.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d94326-9727-41ec-8f5c-fa3d5a457849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from google.ads.googleads.client import GoogleAdsClient\n",
    "from google.ads.googleads.errors import GoogleAdsException\n",
    "\n",
    "_DEFAULT_LOCATION_IDS = [\"2792\"] # tÃ¼rkiye: [\"2792\"], \"1037\" | | Ä°ngiltere: [\"2826\"], \"1000\"  Other country codes: https://developers.google.com/google-ads/api/data/geotargets | | Other Language Codes: https://developers.google.com/google-ads/api/data/codes-formats\n",
    "_DEFAULT_LANGUAGE_ID = \"1037\"\n",
    "\n",
    "def main(\n",
    "    client, customer_id, location_ids, language_id, keyword_texts, page_url\n",
    "):\n",
    "    keyword_plan_idea_service = client.get_service(\"KeywordPlanIdeaService\")\n",
    "    keyword_competition_level_enum = (\n",
    "        client.enums.KeywordPlanCompetitionLevelEnum\n",
    "    )\n",
    "    \n",
    "    keyword_annotation = [(\n",
    "        client.enums.KeywordPlanKeywordAnnotationEnum.KEYWORD_CONCEPT\n",
    "    )]\n",
    "    \n",
    "    keyword_plan_network = (\n",
    "        client.enums.KeywordPlanNetworkEnum.GOOGLE_SEARCH\n",
    "    )\n",
    "    \n",
    "    location_rns = map_locations_ids_to_resource_names(client, location_ids)\n",
    "    language_rn = client.get_service(\"GoogleAdsService\").language_constant_path(\n",
    "        language_id\n",
    "    )\n",
    "\n",
    "    if not (keyword_texts or page_url):\n",
    "        raise ValueError(\n",
    "            \"At least one of keywords or page URL is required, \"\n",
    "            \"but neither was specified.\"\n",
    "        )\n",
    "        \n",
    "    request = client.get_type(\"GenerateKeywordIdeasRequest\")\n",
    "    request.customer_id = customer_id\n",
    "    request.language = language_rn\n",
    "    request.geo_target_constants = location_rns\n",
    "    request.include_adult_keywords = False\n",
    "    request.keyword_plan_network = keyword_plan_network\n",
    "    request.keyword_annotation = keyword_annotation\n",
    "\n",
    "    if not keyword_texts and page_url:\n",
    "        request.url_seed.url = page_url\n",
    "\n",
    "    if keyword_texts and not page_url:\n",
    "        request.keyword_seed.keywords.extend(keyword_texts)\n",
    "\n",
    "    if keyword_texts and page_url:\n",
    "        request.keyword_and_url_seed.url = page_url\n",
    "        request.keyword_and_url_seed.keywords.extend(keyword_texts)\n",
    "\n",
    "    keyword_ideas = keyword_plan_idea_service.generate_keyword_ideas(\n",
    "        request=request\n",
    "    )\n",
    "\n",
    "    keyword_ideas = list(keyword_ideas)\n",
    "    formatted_data = {}\n",
    "    exact_keyword = [{\n",
    "            \"monthlysearch\": keyword_ideas[0].keyword_idea_metrics.avg_monthly_searches,\n",
    "            \"keyword\": keyword_ideas[0].text,\n",
    "            \"difficulty\": keyword_ideas[0].keyword_idea_metrics.competition.name,\n",
    "            \"competition_score\":keyword_ideas[0].keyword_idea_metrics.competition_index,\n",
    "            \"annotation\" : str(keyword_ideas[0].keyword_annotations)\n",
    "        }]\n",
    "    formatted_data['exact_keyword'] = (exact_keyword)\n",
    "    related_keywords = []\n",
    "    for idea in keyword_ideas[1:]:\n",
    "        competition_value = idea.keyword_idea_metrics.competition.name\n",
    "        related_keywords.append({\n",
    "            \"keyword\": idea.text,\n",
    "            \"monthlysearch\": idea.keyword_idea_metrics.avg_monthly_searches,\n",
    "            \"difficulty\": competition_value,\n",
    "            \"competition_score\":idea.keyword_idea_metrics.competition_index,\n",
    "            \"annotation\" : str(idea.keyword_annotations)\n",
    "        })\n",
    "    formatted_data['related_keywords'] = related_keywords\n",
    "    return formatted_data\n",
    "\n",
    "def map_locations_ids_to_resource_names(client, location_ids):\n",
    "    build_resource_name = client.get_service(\n",
    "        \"GeoTargetConstantService\"\n",
    "    ).geo_target_constant_path\n",
    "    return [build_resource_name(location_id) for location_id in location_ids]\n",
    "\n",
    "def start(keyword):\n",
    "\n",
    "    googleads_client = GoogleAdsClient.load_from_storage(\"google-ads.yaml\")\n",
    "\n",
    "    customer_id = 'xxxxxxxxxx' #Enter the account number of your Google Ads test account without -.\n",
    "    keyword_texts = [keyword]\n",
    "    location_ids = _DEFAULT_LOCATION_IDS\n",
    "    language_id = _DEFAULT_LANGUAGE_ID\n",
    "    page_url = None\n",
    "\n",
    "    try:\n",
    "        return main(\n",
    "            googleads_client,\n",
    "            customer_id, \n",
    "            location_ids,\n",
    "            language_id,\n",
    "            keyword_texts,\n",
    "            page_url,\n",
    "        )\n",
    "\n",
    "    except GoogleAdsException as ex:\n",
    "        print(\n",
    "            f'Request with ID \"{ex.request_id}\" failed with status '\n",
    "            f'\"{ex.error.code().name}\" and includes the following errors:'\n",
    "        )\n",
    "        for error in ex.failure.errors:\n",
    "            print(f'\\tError with message \"{error.message}\".')\n",
    "            if error.location:\n",
    "                for field_path_element in error.location.field_path_elements:\n",
    "                    print(f\"\\t\\tOn field: {field_path_element.field_name}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1096e0-6ab1-4c89-845b-5a5181389274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def convert_to_dict(input_str):\n",
    "    pattern = r'concepts {\\n  name: \"(.*?)\"\\n  (concept_group {\\n    .*?\\n  }\\n)}'\n",
    "    matches = re.findall(pattern, input_str, re.DOTALL)\n",
    "    \n",
    "    result = {\"concepts\": []}\n",
    "    for match in matches:\n",
    "        name = match[0]\n",
    "        concept_group_str = match[1]\n",
    "\n",
    "        \n",
    "        pattern = r'name: \"(.*?)\"\\n(    type_: (.*?)\\n)?'\n",
    "        concept_group_matches = re.findall(pattern, concept_group_str, re.DOTALL)\n",
    "        for cg_match in concept_group_matches:\n",
    "            concept_group = {\"name\": cg_match[0]}\n",
    "            if cg_match[1].strip():\n",
    "                concept_group[\"type_\"] = cg_match[1].strip()\n",
    "\n",
    "        concept = {\"name\": name, \"concept_group\": concept_group}\n",
    "        result[\"concepts\"].append(concept)\n",
    "    \n",
    "    return result[\"concepts\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def keyword_row_parser(data):\n",
    "    \"\"\"parse each response into a set of rows.\"\"\";\n",
    "    \n",
    "    final_row = []\n",
    "    base_keyword = data[\"exact_keyword\"][0][\"keyword\"]\n",
    "    base_montlysearch = data[\"exact_keyword\"][0][\"monthlysearch\"]\n",
    "    based_difficulty = data[\"exact_keyword\"][0][\"difficulty\"]\n",
    "    base_competition_score = data[\"exact_keyword\"][0][\"competition_score\"]\n",
    "    base_annotation = data[\"exact_keyword\"][0][\"annotation\"]\n",
    "    \n",
    "    initial_data = {\n",
    "                    \"base_keyword\": base_keyword,\n",
    "                    \"base_montly_search\": base_montlysearch,\n",
    "                    \"based_difficulty\": based_difficulty,\n",
    "                    \"base_competition_score\": base_competition_score,\n",
    "                    \"related_keyword\": base_keyword,\n",
    "                    \"rk_monthly_search\":base_montlysearch,\n",
    "                    \"difficulty\": based_difficulty,\n",
    "                    \"competition_score\": base_competition_score,\n",
    "                    \"annotation\": base_annotation,\n",
    "                    \"name\":None,\n",
    "                    \"concept_name\": None,\n",
    "                    \"concept_type\": None,\n",
    "                    }\n",
    "            \n",
    "    final_row.append(initial_data)\n",
    "    \n",
    "    for item in data[\"related_keywords\"]:\n",
    "        related_keyword = item[\"keyword\"]\n",
    "        rk_monthly_search = item[\"monthlysearch\"]\n",
    "        difficulty = item[\"difficulty\"]\n",
    "        competition_score = item[\"competition_score\"]\n",
    "        \n",
    "        annotation = item[\"annotation\"]\n",
    "        \n",
    "        try:\n",
    "            concept_list = convert_to_dict(annotation)\n",
    "            for item in concept_list:\n",
    "                \n",
    "                name = item[\"name\"]\n",
    "                concept_name = item[\"concept_group\"][\"name\"]\n",
    "                concept_type = item[\"concept_group\"][\"type_\"]\n",
    "\n",
    "                data = {\n",
    "                    \"base_keyword\": base_keyword,\n",
    "                    \"base_montly_search\": base_montlysearch,\n",
    "                    \"based_difficulty\": based_difficulty,\n",
    "                    \"base_competition_score\": base_competition_score,\n",
    "                    \"related_keyword\": related_keyword,\n",
    "                    \"rk_monthly_search\":rk_monthly_search,\n",
    "                    \"difficulty\": difficulty,\n",
    "                    \"competition_score\": competition_score,\n",
    "                    \"annotation\": annotation,\n",
    "                    \"name\":name,\n",
    "                    \"concept_name\": concept_name,\n",
    "                    \"concept_type\": concept_type,\n",
    "                    }\n",
    "                \n",
    "                final_row.append(data)\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "    return final_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f85e0c94-d810-40b0-adea-8f41eeda55c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Enter the name of your CSV file ðŸ‘‡ \n",
    "input_data = pd.read_csv(\"dosya_adi.csv\", header=None) \n",
    "\n",
    "seed_terms = [x for x in input_data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4d34e-b966-471c-88c0-010f5d033f31",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.ads.googleads.client import GoogleAdsClient\n",
    "import time\n",
    "\n",
    "client = GoogleAdsClient.load_from_storage(\"google-ads.yaml\")\n",
    "list_keywords = []\n",
    "failed_terms = []  \n",
    "retry_count = 5\n",
    "\n",
    "\n",
    "for x in seed_terms[0:1000]:\n",
    "    retries = 0\n",
    "    while retries < retry_count:\n",
    "        try:\n",
    "            print(f\"Seed terim {x} iÃ§in {retries + 1}. deneme API isteÄŸi gÃ¶nderiliyor...\") \n",
    "            result = main(client, \"xxxxxxxxxx\", [\"2792\"], \"1037\", [x], None) #Enter the account number of your Google Ads test account without -. Language and country code for Turkey: [\"2792\"], \"1037\"\n",
    "            print(f\"Seed terim {x} iÃ§in API isteÄŸi baÅŸarÄ±lÄ±.\")  \n",
    "            parse_result = keyword_row_parser(result)\n",
    "            list_keywords.extend(parse_result)\n",
    "            break \n",
    "        except Exception as e:\n",
    "            print(f\"Hata: {e}, Terim: {x}, Deneme: {retries + 1}\")\n",
    "            retries += 1\n",
    "            time.sleep(3)\n",
    "\n",
    "    if retries == retry_count:\n",
    "        failed_terms.append(x)\n",
    "\n",
    "print(\"Hata alan seed terimleri:\", failed_terms)\n",
    "\n",
    "\n",
    "for x in failed_terms[0:1000]:\n",
    "    retries = 0\n",
    "    while retries < retry_count:\n",
    "        try:\n",
    "            print(f\"Hatayla karÅŸÄ±laÅŸan terim {x} iÃ§in {retries + 1}. deneme API isteÄŸi gÃ¶nderiliyor...\") \n",
    "            result = main(client, \"xxxxxxxxxx\", [\"2792\"], \"1037\", [x], None) #Enter the account number of your Google Ads test account without -. Language and country code for Turkey: [\"2792\"], \"1037\"\n",
    "            print(f\"Hatayla karÅŸÄ±laÅŸan terim {x} iÃ§in API isteÄŸi baÅŸarÄ±lÄ±.\") \n",
    "            parse_result = keyword_row_parser(result)\n",
    "            list_keywords.extend(parse_result)\n",
    "            break  \n",
    "        except Exception as e:\n",
    "            print(f\"Hata: {e}, Terim: {x}, Deneme: {retries + 1}\")\n",
    "            retries += 1\n",
    "            time.sleep(4)  \n",
    "\n",
    "    if retries == retry_count:\n",
    "        print(f\"Terim {x} iÃ§in tekrar deneme baÅŸarÄ±sÄ±z.\")\n",
    "\n",
    "print(\"TÃ¼m seed terimleri iÃ§in API verileri:\", list_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46adcdf4-21a2-440a-bb0c-4d3c70001d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_data = pd.DataFrame(list_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc3e0d5-a420-4b67-b749-d44e7b8d5437",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Google Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7030e",
   "metadata": {},
   "source": [
    "It takes Google's autocomplete suggestions by adding the letters and numbers \"abcdefghijklmnopqrstuvwxyz0123456789\" one by one at the beginning and end of each keyword you enter for keyword research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdc663e-f139-4532-b19b-c5edac6f3cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import requests\n",
    "import string\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2196666-d672-4783-b00b-b0d8c30f7f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f7e0087-5d9b-4146-a21d-b64c87148938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WAIT_TIME = 0.1\n",
    "MAX_WORKERS = 20\n",
    "\n",
    "# Enter the language you want to target below ðŸ‘‡\n",
    "lang = \"tr\"\n",
    "\n",
    "charList = \" \" + string.ascii_lowercase + string.digits\n",
    "\n",
    "def makeGoogleRequest(query):\n",
    "     \n",
    "    time.sleep(WAIT_TIME)\n",
    "    URL=\"https://google.com/complete/search\"   \n",
    "    PARAMS = {\"client\":\"firefox\",\n",
    "            \"hl\":lang,\n",
    "            \"q\":query}\n",
    "    headers = {'User-agent':'Mozilla/5.0'}\n",
    "    response = requests.get(URL, params=PARAMS, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        suggestedSearches = json.loads(response.content.decode('utf-8'))[1]\n",
    "        return suggestedSearches\n",
    "    else:\n",
    "        return \"ERR\"\n",
    "\n",
    "def getGoogleSuggests(keyword):\n",
    "    \n",
    "    queryList = [keyword + \" \" + char for char in charList] + [char + \" \" + keyword for char in charList]\n",
    "    suggestions = []\n",
    "    for query in queryList:\n",
    "        suggestion = makeGoogleRequest(query)\n",
    "        if suggestion != 'ERR':\n",
    "            suggestions.append(suggestion)\n",
    "\n",
    "    \n",
    "    suggestions = set(itertools.chain(*suggestions))\n",
    "    if \"\" in suggestions:\n",
    "        suggestions.remove(\"\")\n",
    "\n",
    "    return suggestions\n",
    "\n",
    "\n",
    "\n",
    "keywords = seed_terms \n",
    "\n",
    "resultList = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futuresGoogle = {executor.submit(getGoogleSuggests, keyword): keyword for keyword in keywords}\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futuresGoogle):\n",
    "        key = futuresGoogle[future]\n",
    "        for suggestion in future.result():\n",
    "            resultList.append([key, suggestion])\n",
    "\n",
    "\n",
    "outputDf = pd.DataFrame(resultList, columns=['Keyword','Suggestion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3efa9e8d-8ea0-4d07-8f52-95a179484349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "\n",
    "final['main_kw'] = pd.concat([output_data['base_keyword'], outputDf['Keyword']], ignore_index=True)\n",
    "\n",
    "\n",
    "final['related_keyword'] = pd.concat([output_data['related_keyword'], outputDf['Suggestion']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d657b7-4c9e-4607-962c-4f1ae3826948",
   "metadata": {},
   "source": [
    "# Gemini Semantic Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f66101",
   "metadata": {},
   "source": [
    "https://aistudio.google.com/app/prompts/new_chat upload the sheet to the address as in the example format below and run the following prompt. The prompt asks for 5 keyword suggestions for each word. You can increase this number if you want.\n",
    "\n",
    "Sample CSV format to be transmitted to Gemini: https://docs.google.com/spreadsheets/d/19yzrez75KQmZ7W0iFB6MPooSxEDjiuzjEdhPfXxScXc/edit?usp=sharing \n",
    "\n",
    "Prompt ðŸ‘‡\n",
    "\n",
    "*This CSV file has two columns, Keywords and Related Keywords. For each word in the Keywords column, I want you to write five semantic words that mean the same thing as these words in the Related Keywords column opposite it. These words should be both related and related to how else people might search for these words in Google. You should write these words side by side in the relevant row, separated by commas. Don't write any extra explanations. Just write the words and send me the edited csv file again.*\n",
    "\n",
    "Gemini will return you a response as in the picture at https://prnt.sc/vdqD80gd6JnI. Here, starting from the Keywords section, load the relevant part into the data = field in the code block below. You can view the sample format below. You can delete this part and copy and paste the response from Gemini in the same format into this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2560a5e-ae5b-44da-85a1-67c90c69b305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = \"\"\"Keywords,Related Keywords\n",
    "arkadaÅŸlarla oynanacak oyunlar,Ã§ok oyunculu oyunlar, Ã§evrimiÃ§i oyunlar, arkadaÅŸlarla oynanabilecek oyunlar, birlikte oynanacak oyunlar, multiplayer oyunlar\n",
    "klavye kÄ±sayollarÄ±, klavyeden kÄ±sayollar, klavye hileleri, kÄ±sayol tuÅŸlarÄ±, pc kÄ±sayollarÄ±, bilgisayar kÄ±sayollarÄ±\n",
    "google hileleri, google arama hileleri, google aramalarÄ±, google arama motorunda hileler, google aramalarÄ± iÃ§in hileler, google search hileleri\n",
    "instagram keÅŸfet sÄ±fÄ±rlama, instagram keÅŸfet algoritmasÄ±, instagram keÅŸfet algoritmasÄ± sÄ±fÄ±rlama, instagram keÅŸfet sÄ±fÄ±rla, instagram keÅŸfet feed'ini sÄ±fÄ±rla, instagram keÅŸfet algoritmasÄ±nÄ± sÄ±fÄ±rla\n",
    "instagram kullanÄ±cÄ± adÄ± deÄŸiÅŸtirme, instagramda kullanÄ±cÄ± adÄ± deÄŸiÅŸtirme, instagram username deÄŸiÅŸtirme, instagram kullanÄ±cÄ± adÄ± nasÄ±l deÄŸiÅŸtirilir, instagramda kullanÄ±cÄ± adÄ± nasÄ±l deÄŸiÅŸtirilir, instagramda kullanÄ±cÄ± adÄ± deÄŸiÅŸtirme iÅŸlemi\n",
    "wifi ÅŸifresi Ã¶ÄŸrenme, wifi ÅŸifresini Ã¶ÄŸrenme, wifi ÅŸifresi bulma, wifi ÅŸifresini gÃ¶rme, kablosuz ÅŸifre bulma, wifi aÄŸ ÅŸifresi bulma\n",
    "vsync nedir, vsync aÃ§Ä±klamasÄ±, vsync ne iÅŸe yarar, vsync ayarlarÄ±, vsync Ã¶zelliÄŸi, vsync ne yapar\n",
    "oem nedir, oem lisans, oem Ã¼rÃ¼n, oem yazÄ±lÄ±m, oem marka, oem versiyon\n",
    "ip adresi deÄŸiÅŸtirme, ip deÄŸiÅŸtirme, ip adresi gizleme, ip adresi deÄŸiÅŸtirme programÄ±, ip adresi nasÄ±l deÄŸiÅŸtirilir, ip adresi deÄŸiÅŸtirme yÃ¶ntemi\n",
    "whatsapp yedeklenen mesajlarÄ± geri getirme, whatsapp yedeÄŸini geri yÃ¼kleme, whatsapp yedek mesajlarÄ± geri yÃ¼kleme, whatsapp mesajlarÄ± geri yÃ¼kleme, whatsapp silinen mesajlarÄ± geri getirme, whatsapp yedekten geri yÃ¼kleme\n",
    "mac adresi nedir, mac adresi ne iÅŸe yarar, mac adres nasÄ±l bulunur, mac adresi Ã¶ÄŸrenme, mac adresi deÄŸiÅŸtirme, mac adresi ne demek\n",
    "tarayÄ±cÄ± oyunlarÄ±, internet oyunlarÄ±, Ã§evrimiÃ§i oyunlar, online oyunlar, browser oyunlarÄ±, web oyunlarÄ±\n",
    "telefon ekranÄ±nÄ± bilgisayara yansÄ±tma, telefon ekranÄ± yansÄ±tma, telefon ekranÄ± paylaÅŸma, telefon ekranÄ± bilgisayara gÃ¶sterme, telefon ekranÄ± aktarma, telefon ekranÄ± bilgisayar ile senkronize etme\n",
    "aÃ§Ä±k dÃ¼nya oyunlarÄ±, sandbox oyunlar, serbest oyunlar, aÃ§Ä±k alan oyunlarÄ±, Ã¼Ã§ boyutlu oyunlar, rol yapma oyunlarÄ±\n",
    "steam hesap deÄŸeri Ã¶ÄŸrenme, steam hesap deÄŸeri nasÄ±l hesaplanÄ±r, steam hesap deÄŸeri kontrol etme, steam hesap deÄŸeri kontrolÃ¼, steam hesap deÄŸeri hesaplama, steam hesabÄ± deÄŸerlendirme\n",
    "silinen dosyalarÄ± geri getirme nasÄ±l yapÄ±lÄ±r, silinen dosyalarÄ± geri yÃ¼kleme, silinen dosyalarÄ± kurtarma, silinen dosyalarÄ± geri getirme programÄ±, silinen dosyalarÄ± geri getirme yÃ¶ntemleri, silinen dosyalarÄ± geri kazandÄ±rma\n",
    "internetsiz oyunlar, offline oyunlar, tek oyunculu oyunlar, Ã§evrimdÄ±ÅŸÄ± oyunlar, bilgisayar oyunlarÄ±, mobil oyunlar\n",
    "whatsapp plus, whatsapp mod, whatsapp mod apk, whatsapp plus apk, whatsapp plus indir, whatsapp mod indir\n",
    "tbt ne demek, tbt anlamÄ±, tbt ne anlama geliyor, tbt ne anlama gelir, tbt kÄ±saltmasÄ±, tbt nedir\n",
    "whatsapp silinen mesajlarÄ± geri getirme, whatsapp yedeÄŸinden mesaj geri yÃ¼kleme, whatsapp silinen mesajlarÄ± kurtarma, whatsapp silinen mesajlarÄ± geri getirme programÄ±, whatsapp silinen mesajlarÄ± geri getirme yÃ¶ntemi, whatsapp silinen mesajlarÄ± geri yÃ¼kleme\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "rows = data.strip().split(\"\\n\")\n",
    "\n",
    "\n",
    "keywords = []\n",
    "related_keywords = []\n",
    "for row in rows[1:]:\n",
    "    keyword, related = row.split(\",\", 1)\n",
    "    keywords.append(keyword)\n",
    "    related_keywords.append(related)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"Keywords\": keywords, \"Related Keywords\": related_keywords})\n",
    "\n",
    "\n",
    "df.index = range(len(df))\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame(columns=[\"Keywords\", \"Related Keywords\"])\n",
    "current_keyword = \"\"\n",
    "for i, row in df.iterrows():\n",
    "    if i == 0:\n",
    "        current_keyword = row[\"Keywords\"]\n",
    "    for related_keyword in row[\"Related Keywords\"].split(\",\"):\n",
    "        new_df = pd.concat([new_df, pd.DataFrame({\"Keywords\": [current_keyword], \"Related Keywords\": [related_keyword.strip()]})], ignore_index=True)\n",
    "    if i < len(df) - 1:\n",
    "        current_keyword = df.loc[i+1, \"Keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52bec6ee-cc2e-46ad-8efd-71967f28b96e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "new_data = pd.DataFrame({\n",
    "    'main_kw': new_df['Keywords'],\n",
    "    'related_keyword': new_df['Related Keywords']\n",
    "})\n",
    "\n",
    "final = pd.concat([final, new_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56c750-0902-4a52-8ca8-6e6e48e23320",
   "metadata": {},
   "source": [
    "# Delete Duplicate Rows in Dataframe and Export All Data in XLSX Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1f077-e7dd-460a-9ebf-0794f76f4637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_row_count = final.shape[0]\n",
    "\n",
    "final = final.drop_duplicates()\n",
    "\n",
    "rows_deleted = original_row_count - final.shape[0]\n",
    "\n",
    "print(f\"Silinen satÄ±r sayÄ±sÄ±: {rows_deleted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "826a4b83-829a-4c23-a957-55cb52099048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final.to_excel('dosya_adi.xlsx') # ðŸ‘ˆ Specify the file name you want to export all this data to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6c4f6-1725-4ca9-a26b-3d5893de3b4e",
   "metadata": {},
   "source": [
    "Copy and paste all keywords in the related_keyword column of this xlsx file into the input field at https://contentgecko.io/free-serp-keyword-clustering. Then select the target country, language and minimum SERP similarity and press the create clusters button. When you enter your e-mail address on the next screen, clustered data will be sent to your e-mail address within two minutes on average. https://prnt.sc/6un7vv3juTlt * 5000 keywords can be clustered at a time. There are no restrictions other than that.\n",
    "\n",
    "Different clustering algorithms can be used here. However, since this tool does the clustering process according to the SERP, we actually act completely according to what Google understands from the relevant search terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a3b7ec-7514-4d3b-8509-22b1a36f8788",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parse a Clustered Keyword File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b65f2f-fc35-4860-a0e2-f7ad12d3e7c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Cluster results will be sent to your e-mail address in xlsx format. (https://prnt.sc/5AfOEJByPHbt) Download this file to your computer and enter the file path in the code block below. This code block will process the xlsx file and extract all keywords belonging to the cluster group in which the keyword you have specified is in. In this way, keywords that are not related to the keyword will be eliminated and you will be able to access the final data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "474377be-5ecf-4d9e-94b7-c3a81c9c582e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Upload the CSV file sent to your e-mail address from contentgecko. ðŸ‘‡\n",
    "df = pd.read_excel('contentgecko-10060-2024-06-17.xlsx') \n",
    "\n",
    "\n",
    "aranan_kelimeler = seed_terms\n",
    "  \n",
    "\n",
    "\n",
    "changed_rows = set()\n",
    "\n",
    "\n",
    "for kelime in aranan_kelimeler:\n",
    "    \n",
    "    matching_rows = df[df['keyword'] == kelime]\n",
    "    \n",
    "    \n",
    "    clusters_to_change = matching_rows['cluster'].unique()\n",
    "    \n",
    "    \n",
    "    for cluster_value in clusters_to_change:\n",
    "        \n",
    "        indices = df.loc[df['cluster'] == cluster_value].index\n",
    "        df.loc[indices, 'cluster'] = kelime\n",
    "        \n",
    "        \n",
    "        changed_rows.update(indices)\n",
    "\n",
    "\n",
    "df_changed = df.loc[sorted(changed_rows)]\n",
    "df_changed = df_changed[df_changed['search_volume'] >= 10] # It deletes those with a search volume of less than 10. You can increase this value if you want.\n",
    "\n",
    "# Enter a file name to save the results in a new CSV file ðŸ‘‡\n",
    "df_changed.to_csv('dosya_adi.csv', index=False)\n",
    "\n",
    "# Created by Anil Burak Karadede (https://www.linkedin.com/in/anilburakkaradede/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
