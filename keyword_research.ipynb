{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929de01-30d1-4216-a1a5-4a72da73ba8e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Created by Anil Burak Karadede (https://www.linkedin.com/in/anilburakkaradede/)\n",
    "pip install google-ads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264183c",
   "metadata": {},
   "source": [
    "# Google Ads API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0582d736-01bd-43c4-b1c8-450a3f027b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.ads.googleads.client import GoogleAdsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad12231-8316-4016-b732-7c2bbd01f101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "googleads_client = GoogleAdsClient.load_from_storage(\"google-ads.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d94326-9727-41ec-8f5c-fa3d5a457849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from google.ads.googleads.client import GoogleAdsClient\n",
    "from google.ads.googleads.errors import GoogleAdsException\n",
    "\n",
    "_DEFAULT_LOCATION_IDS = [\"2792\"] # türkiye: [\"2792\"], \"1037\" | | İngiltere: [\"2826\"], \"1000\"  Other country codes: https://developers.google.com/google-ads/api/data/geotargets | | Other Language Codes: https://developers.google.com/google-ads/api/data/codes-formats\n",
    "_DEFAULT_LANGUAGE_ID = \"1037\"\n",
    "\n",
    "def main(\n",
    "    client, customer_id, location_ids, language_id, keyword_texts, page_url\n",
    "):\n",
    "    keyword_plan_idea_service = client.get_service(\"KeywordPlanIdeaService\")\n",
    "    keyword_competition_level_enum = (\n",
    "        client.enums.KeywordPlanCompetitionLevelEnum\n",
    "    )\n",
    "    \n",
    "    keyword_annotation = [(\n",
    "        client.enums.KeywordPlanKeywordAnnotationEnum.KEYWORD_CONCEPT\n",
    "    )]\n",
    "    \n",
    "    keyword_plan_network = (\n",
    "        client.enums.KeywordPlanNetworkEnum.GOOGLE_SEARCH\n",
    "    )\n",
    "    \n",
    "    location_rns = map_locations_ids_to_resource_names(client, location_ids)\n",
    "    language_rn = client.get_service(\"GoogleAdsService\").language_constant_path(\n",
    "        language_id\n",
    "    )\n",
    "\n",
    "    if not (keyword_texts or page_url):\n",
    "        raise ValueError(\n",
    "            \"At least one of keywords or page URL is required, \"\n",
    "            \"but neither was specified.\"\n",
    "        )\n",
    "        \n",
    "    request = client.get_type(\"GenerateKeywordIdeasRequest\")\n",
    "    request.customer_id = customer_id\n",
    "    request.language = language_rn\n",
    "    request.geo_target_constants = location_rns\n",
    "    request.include_adult_keywords = False\n",
    "    request.keyword_plan_network = keyword_plan_network\n",
    "    request.keyword_annotation = keyword_annotation\n",
    "\n",
    "    if not keyword_texts and page_url:\n",
    "        request.url_seed.url = page_url\n",
    "\n",
    "    if keyword_texts and not page_url:\n",
    "        request.keyword_seed.keywords.extend(keyword_texts)\n",
    "\n",
    "    if keyword_texts and page_url:\n",
    "        request.keyword_and_url_seed.url = page_url\n",
    "        request.keyword_and_url_seed.keywords.extend(keyword_texts)\n",
    "\n",
    "    keyword_ideas = keyword_plan_idea_service.generate_keyword_ideas(\n",
    "        request=request\n",
    "    )\n",
    "\n",
    "    keyword_ideas = list(keyword_ideas)\n",
    "    formatted_data = {}\n",
    "    exact_keyword = [{\n",
    "            \"monthlysearch\": keyword_ideas[0].keyword_idea_metrics.avg_monthly_searches,\n",
    "            \"keyword\": keyword_ideas[0].text,\n",
    "            \"difficulty\": keyword_ideas[0].keyword_idea_metrics.competition.name,\n",
    "            \"competition_score\":keyword_ideas[0].keyword_idea_metrics.competition_index,\n",
    "            \"annotation\" : str(keyword_ideas[0].keyword_annotations)\n",
    "        }]\n",
    "    formatted_data['exact_keyword'] = (exact_keyword)\n",
    "    related_keywords = []\n",
    "    for idea in keyword_ideas[1:]:\n",
    "        competition_value = idea.keyword_idea_metrics.competition.name\n",
    "        related_keywords.append({\n",
    "            \"keyword\": idea.text,\n",
    "            \"monthlysearch\": idea.keyword_idea_metrics.avg_monthly_searches,\n",
    "            \"difficulty\": competition_value,\n",
    "            \"competition_score\":idea.keyword_idea_metrics.competition_index,\n",
    "            \"annotation\" : str(idea.keyword_annotations)\n",
    "        })\n",
    "    formatted_data['related_keywords'] = related_keywords\n",
    "    return formatted_data\n",
    "\n",
    "def map_locations_ids_to_resource_names(client, location_ids):\n",
    "    build_resource_name = client.get_service(\n",
    "        \"GeoTargetConstantService\"\n",
    "    ).geo_target_constant_path\n",
    "    return [build_resource_name(location_id) for location_id in location_ids]\n",
    "\n",
    "def start(keyword):\n",
    "\n",
    "    googleads_client = GoogleAdsClient.load_from_storage(\"google-ads.yaml\")\n",
    "\n",
    "    customer_id = 'xxxxxxxxxx' #Enter the account number of your Google Ads test account without -.\n",
    "    keyword_texts = [keyword]\n",
    "    location_ids = _DEFAULT_LOCATION_IDS\n",
    "    language_id = _DEFAULT_LANGUAGE_ID\n",
    "    page_url = None\n",
    "\n",
    "    try:\n",
    "        return main(\n",
    "            googleads_client,\n",
    "            customer_id, \n",
    "            location_ids,\n",
    "            language_id,\n",
    "            keyword_texts,\n",
    "            page_url,\n",
    "        )\n",
    "\n",
    "    except GoogleAdsException as ex:\n",
    "        print(\n",
    "            f'Request with ID \"{ex.request_id}\" failed with status '\n",
    "            f'\"{ex.error.code().name}\" and includes the following errors:'\n",
    "        )\n",
    "        for error in ex.failure.errors:\n",
    "            print(f'\\tError with message \"{error.message}\".')\n",
    "            if error.location:\n",
    "                for field_path_element in error.location.field_path_elements:\n",
    "                    print(f\"\\t\\tOn field: {field_path_element.field_name}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1096e0-6ab1-4c89-845b-5a5181389274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def convert_to_dict(input_str):\n",
    "    pattern = r'concepts {\\n  name: \"(.*?)\"\\n  (concept_group {\\n    .*?\\n  }\\n)}'\n",
    "    matches = re.findall(pattern, input_str, re.DOTALL)\n",
    "    \n",
    "    result = {\"concepts\": []}\n",
    "    for match in matches:\n",
    "        name = match[0]\n",
    "        concept_group_str = match[1]\n",
    "\n",
    "        \n",
    "        pattern = r'name: \"(.*?)\"\\n(    type_: (.*?)\\n)?'\n",
    "        concept_group_matches = re.findall(pattern, concept_group_str, re.DOTALL)\n",
    "        for cg_match in concept_group_matches:\n",
    "            concept_group = {\"name\": cg_match[0]}\n",
    "            if cg_match[1].strip():\n",
    "                concept_group[\"type_\"] = cg_match[1].strip()\n",
    "\n",
    "        concept = {\"name\": name, \"concept_group\": concept_group}\n",
    "        result[\"concepts\"].append(concept)\n",
    "    \n",
    "    return result[\"concepts\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def keyword_row_parser(data):\n",
    "    \"\"\"parse each response into a set of rows.\"\"\";\n",
    "    \n",
    "    final_row = []\n",
    "    base_keyword = data[\"exact_keyword\"][0][\"keyword\"]\n",
    "    base_montlysearch = data[\"exact_keyword\"][0][\"monthlysearch\"]\n",
    "    based_difficulty = data[\"exact_keyword\"][0][\"difficulty\"]\n",
    "    base_competition_score = data[\"exact_keyword\"][0][\"competition_score\"]\n",
    "    base_annotation = data[\"exact_keyword\"][0][\"annotation\"]\n",
    "    \n",
    "    initial_data = {\n",
    "                    \"base_keyword\": base_keyword,\n",
    "                    \"base_montly_search\": base_montlysearch,\n",
    "                    \"based_difficulty\": based_difficulty,\n",
    "                    \"base_competition_score\": base_competition_score,\n",
    "                    \"related_keyword\": base_keyword,\n",
    "                    \"rk_monthly_search\":base_montlysearch,\n",
    "                    \"difficulty\": based_difficulty,\n",
    "                    \"competition_score\": base_competition_score,\n",
    "                    \"annotation\": base_annotation,\n",
    "                    \"name\":None,\n",
    "                    \"concept_name\": None,\n",
    "                    \"concept_type\": None,\n",
    "                    }\n",
    "            \n",
    "    final_row.append(initial_data)\n",
    "    \n",
    "    for item in data[\"related_keywords\"]:\n",
    "        related_keyword = item[\"keyword\"]\n",
    "        rk_monthly_search = item[\"monthlysearch\"]\n",
    "        difficulty = item[\"difficulty\"]\n",
    "        competition_score = item[\"competition_score\"]\n",
    "        \n",
    "        annotation = item[\"annotation\"]\n",
    "        \n",
    "        try:\n",
    "            concept_list = convert_to_dict(annotation)\n",
    "            for item in concept_list:\n",
    "                \n",
    "                name = item[\"name\"]\n",
    "                concept_name = item[\"concept_group\"][\"name\"]\n",
    "                concept_type = item[\"concept_group\"][\"type_\"]\n",
    "\n",
    "                data = {\n",
    "                    \"base_keyword\": base_keyword,\n",
    "                    \"base_montly_search\": base_montlysearch,\n",
    "                    \"based_difficulty\": based_difficulty,\n",
    "                    \"base_competition_score\": base_competition_score,\n",
    "                    \"related_keyword\": related_keyword,\n",
    "                    \"rk_monthly_search\":rk_monthly_search,\n",
    "                    \"difficulty\": difficulty,\n",
    "                    \"competition_score\": competition_score,\n",
    "                    \"annotation\": annotation,\n",
    "                    \"name\":name,\n",
    "                    \"concept_name\": concept_name,\n",
    "                    \"concept_type\": concept_type,\n",
    "                    }\n",
    "                \n",
    "                final_row.append(data)\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "    return final_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f85e0c94-d810-40b0-adea-8f41eeda55c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Enter the name of your CSV file 👇 \n",
    "input_data = pd.read_csv(\"dosya_adi.csv\", header=None) \n",
    "\n",
    "seed_terms = [x for x in input_data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4d34e-b966-471c-88c0-010f5d033f31",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.ads.googleads.client import GoogleAdsClient\n",
    "import time\n",
    "\n",
    "client = GoogleAdsClient.load_from_storage(\"google-ads.yaml\")\n",
    "list_keywords = []\n",
    "failed_terms = []  \n",
    "retry_count = 5\n",
    "\n",
    "\n",
    "for x in seed_terms[0:1000]:\n",
    "    retries = 0\n",
    "    while retries < retry_count:\n",
    "        try:\n",
    "            print(f\"Seed terim {x} için {retries + 1}. deneme API isteği gönderiliyor...\") \n",
    "            result = main(client, \"xxxxxxxxxx\", [\"2792\"], \"1037\", [x], None) #Enter the account number of your Google Ads test account without -. Language and country code for Turkey: [\"2792\"], \"1037\"\n",
    "            print(f\"Seed terim {x} için API isteği başarılı.\")  \n",
    "            parse_result = keyword_row_parser(result)\n",
    "            list_keywords.extend(parse_result)\n",
    "            break \n",
    "        except Exception as e:\n",
    "            print(f\"Hata: {e}, Terim: {x}, Deneme: {retries + 1}\")\n",
    "            retries += 1\n",
    "            time.sleep(3)\n",
    "\n",
    "    if retries == retry_count:\n",
    "        failed_terms.append(x)\n",
    "\n",
    "print(\"Hata alan seed terimleri:\", failed_terms)\n",
    "\n",
    "\n",
    "for x in failed_terms[0:1000]:\n",
    "    retries = 0\n",
    "    while retries < retry_count:\n",
    "        try:\n",
    "            print(f\"Hatayla karşılaşan terim {x} için {retries + 1}. deneme API isteği gönderiliyor...\") \n",
    "            result = main(client, \"xxxxxxxxxx\", [\"2792\"], \"1037\", [x], None) #Enter the account number of your Google Ads test account without -. Language and country code for Turkey: [\"2792\"], \"1037\"\n",
    "            print(f\"Hatayla karşılaşan terim {x} için API isteği başarılı.\") \n",
    "            parse_result = keyword_row_parser(result)\n",
    "            list_keywords.extend(parse_result)\n",
    "            break  \n",
    "        except Exception as e:\n",
    "            print(f\"Hata: {e}, Terim: {x}, Deneme: {retries + 1}\")\n",
    "            retries += 1\n",
    "            time.sleep(4)  \n",
    "\n",
    "    if retries == retry_count:\n",
    "        print(f\"Terim {x} için tekrar deneme başarısız.\")\n",
    "\n",
    "print(\"Tüm seed terimleri için API verileri:\", list_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46adcdf4-21a2-440a-bb0c-4d3c70001d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_data = pd.DataFrame(list_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc3e0d5-a420-4b67-b749-d44e7b8d5437",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Google Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7030e",
   "metadata": {},
   "source": [
    "It takes Google's autocomplete suggestions by adding the letters and numbers \"abcdefghijklmnopqrstuvwxyz0123456789\" one by one at the beginning and end of each keyword you enter for keyword research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdc663e-f139-4532-b19b-c5edac6f3cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import requests\n",
    "import string\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2196666-d672-4783-b00b-b0d8c30f7f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f7e0087-5d9b-4146-a21d-b64c87148938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WAIT_TIME = 0.1\n",
    "MAX_WORKERS = 20\n",
    "\n",
    "# Enter the language you want to target below 👇\n",
    "lang = \"tr\"\n",
    "\n",
    "charList = \" \" + string.ascii_lowercase + string.digits\n",
    "\n",
    "def makeGoogleRequest(query):\n",
    "     \n",
    "    time.sleep(WAIT_TIME)\n",
    "    URL=\"https://google.com/complete/search\"   \n",
    "    PARAMS = {\"client\":\"firefox\",\n",
    "            \"hl\":lang,\n",
    "            \"q\":query}\n",
    "    headers = {'User-agent':'Mozilla/5.0'}\n",
    "    response = requests.get(URL, params=PARAMS, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        suggestedSearches = json.loads(response.content.decode('utf-8'))[1]\n",
    "        return suggestedSearches\n",
    "    else:\n",
    "        return \"ERR\"\n",
    "\n",
    "def getGoogleSuggests(keyword):\n",
    "    \n",
    "    queryList = [keyword + \" \" + char for char in charList] + [char + \" \" + keyword for char in charList]\n",
    "    suggestions = []\n",
    "    for query in queryList:\n",
    "        suggestion = makeGoogleRequest(query)\n",
    "        if suggestion != 'ERR':\n",
    "            suggestions.append(suggestion)\n",
    "\n",
    "    \n",
    "    suggestions = set(itertools.chain(*suggestions))\n",
    "    if \"\" in suggestions:\n",
    "        suggestions.remove(\"\")\n",
    "\n",
    "    return suggestions\n",
    "\n",
    "\n",
    "\n",
    "keywords = seed_terms \n",
    "\n",
    "resultList = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futuresGoogle = {executor.submit(getGoogleSuggests, keyword): keyword for keyword in keywords}\n",
    "\n",
    "    for future in concurrent.futures.as_completed(futuresGoogle):\n",
    "        key = futuresGoogle[future]\n",
    "        for suggestion in future.result():\n",
    "            resultList.append([key, suggestion])\n",
    "\n",
    "\n",
    "outputDf = pd.DataFrame(resultList, columns=['Keyword','Suggestion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3efa9e8d-8ea0-4d07-8f52-95a179484349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "\n",
    "final['main_kw'] = pd.concat([output_data['base_keyword'], outputDf['Keyword']], ignore_index=True)\n",
    "\n",
    "\n",
    "final['related_keyword'] = pd.concat([output_data['related_keyword'], outputDf['Suggestion']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d657b7-4c9e-4607-962c-4f1ae3826948",
   "metadata": {},
   "source": [
    "# Gemini Semantic Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f66101",
   "metadata": {},
   "source": [
    "https://aistudio.google.com/app/prompts/new_chat upload the sheet to the address as in the example format below and run the following prompt. The prompt asks for 5 keyword suggestions for each word. You can increase this number if you want.\n",
    "\n",
    "Sample CSV format to be transmitted to Gemini: https://docs.google.com/spreadsheets/d/19yzrez75KQmZ7W0iFB6MPooSxEDjiuzjEdhPfXxScXc/edit?usp=sharing \n",
    "\n",
    "Prompt 👇\n",
    "\n",
    "*This CSV file has two columns, Keywords and Related Keywords. For each word in the Keywords column, I want you to write five semantic words that mean the same thing as these words in the Related Keywords column opposite it. These words should be both related and related to how else people might search for these words in Google. You should write these words side by side in the relevant row, separated by commas. Don't write any extra explanations. Just write the words and send me the edited csv file again.*\n",
    "\n",
    "Gemini will return you a response as in the picture at https://prnt.sc/vdqD80gd6JnI. Here, starting from the Keywords section, load the relevant part into the data = field in the code block below. You can view the sample format below. You can delete this part and copy and paste the response from Gemini in the same format into this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2560a5e-ae5b-44da-85a1-67c90c69b305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = \"\"\"Keywords,Related Keywords\n",
    "arkadaşlarla oynanacak oyunlar,çok oyunculu oyunlar, çevrimiçi oyunlar, arkadaşlarla oynanabilecek oyunlar, birlikte oynanacak oyunlar, multiplayer oyunlar\n",
    "klavye kısayolları, klavyeden kısayollar, klavye hileleri, kısayol tuşları, pc kısayolları, bilgisayar kısayolları\n",
    "google hileleri, google arama hileleri, google aramaları, google arama motorunda hileler, google aramaları için hileler, google search hileleri\n",
    "instagram keşfet sıfırlama, instagram keşfet algoritması, instagram keşfet algoritması sıfırlama, instagram keşfet sıfırla, instagram keşfet feed'ini sıfırla, instagram keşfet algoritmasını sıfırla\n",
    "instagram kullanıcı adı değiştirme, instagramda kullanıcı adı değiştirme, instagram username değiştirme, instagram kullanıcı adı nasıl değiştirilir, instagramda kullanıcı adı nasıl değiştirilir, instagramda kullanıcı adı değiştirme işlemi\n",
    "wifi şifresi öğrenme, wifi şifresini öğrenme, wifi şifresi bulma, wifi şifresini görme, kablosuz şifre bulma, wifi ağ şifresi bulma\n",
    "vsync nedir, vsync açıklaması, vsync ne işe yarar, vsync ayarları, vsync özelliği, vsync ne yapar\n",
    "oem nedir, oem lisans, oem ürün, oem yazılım, oem marka, oem versiyon\n",
    "ip adresi değiştirme, ip değiştirme, ip adresi gizleme, ip adresi değiştirme programı, ip adresi nasıl değiştirilir, ip adresi değiştirme yöntemi\n",
    "whatsapp yedeklenen mesajları geri getirme, whatsapp yedeğini geri yükleme, whatsapp yedek mesajları geri yükleme, whatsapp mesajları geri yükleme, whatsapp silinen mesajları geri getirme, whatsapp yedekten geri yükleme\n",
    "mac adresi nedir, mac adresi ne işe yarar, mac adres nasıl bulunur, mac adresi öğrenme, mac adresi değiştirme, mac adresi ne demek\n",
    "tarayıcı oyunları, internet oyunları, çevrimiçi oyunlar, online oyunlar, browser oyunları, web oyunları\n",
    "telefon ekranını bilgisayara yansıtma, telefon ekranı yansıtma, telefon ekranı paylaşma, telefon ekranı bilgisayara gösterme, telefon ekranı aktarma, telefon ekranı bilgisayar ile senkronize etme\n",
    "açık dünya oyunları, sandbox oyunlar, serbest oyunlar, açık alan oyunları, üç boyutlu oyunlar, rol yapma oyunları\n",
    "steam hesap değeri öğrenme, steam hesap değeri nasıl hesaplanır, steam hesap değeri kontrol etme, steam hesap değeri kontrolü, steam hesap değeri hesaplama, steam hesabı değerlendirme\n",
    "silinen dosyaları geri getirme nasıl yapılır, silinen dosyaları geri yükleme, silinen dosyaları kurtarma, silinen dosyaları geri getirme programı, silinen dosyaları geri getirme yöntemleri, silinen dosyaları geri kazandırma\n",
    "internetsiz oyunlar, offline oyunlar, tek oyunculu oyunlar, çevrimdışı oyunlar, bilgisayar oyunları, mobil oyunlar\n",
    "whatsapp plus, whatsapp mod, whatsapp mod apk, whatsapp plus apk, whatsapp plus indir, whatsapp mod indir\n",
    "tbt ne demek, tbt anlamı, tbt ne anlama geliyor, tbt ne anlama gelir, tbt kısaltması, tbt nedir\n",
    "whatsapp silinen mesajları geri getirme, whatsapp yedeğinden mesaj geri yükleme, whatsapp silinen mesajları kurtarma, whatsapp silinen mesajları geri getirme programı, whatsapp silinen mesajları geri getirme yöntemi, whatsapp silinen mesajları geri yükleme\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "rows = data.strip().split(\"\\n\")\n",
    "\n",
    "\n",
    "keywords = []\n",
    "related_keywords = []\n",
    "for row in rows[1:]:\n",
    "    keyword, related = row.split(\",\", 1)\n",
    "    keywords.append(keyword)\n",
    "    related_keywords.append(related)\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"Keywords\": keywords, \"Related Keywords\": related_keywords})\n",
    "\n",
    "\n",
    "df.index = range(len(df))\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame(columns=[\"Keywords\", \"Related Keywords\"])\n",
    "current_keyword = \"\"\n",
    "for i, row in df.iterrows():\n",
    "    if i == 0:\n",
    "        current_keyword = row[\"Keywords\"]\n",
    "    for related_keyword in row[\"Related Keywords\"].split(\",\"):\n",
    "        new_df = pd.concat([new_df, pd.DataFrame({\"Keywords\": [current_keyword], \"Related Keywords\": [related_keyword.strip()]})], ignore_index=True)\n",
    "    if i < len(df) - 1:\n",
    "        current_keyword = df.loc[i+1, \"Keywords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52bec6ee-cc2e-46ad-8efd-71967f28b96e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "new_data = pd.DataFrame({\n",
    "    'main_kw': new_df['Keywords'],\n",
    "    'related_keyword': new_df['Related Keywords']\n",
    "})\n",
    "\n",
    "final = pd.concat([final, new_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56c750-0902-4a52-8ca8-6e6e48e23320",
   "metadata": {},
   "source": [
    "# Delete Duplicate Rows in Dataframe and Export All Data in XLSX Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1f077-e7dd-460a-9ebf-0794f76f4637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_row_count = final.shape[0]\n",
    "\n",
    "final = final.drop_duplicates()\n",
    "\n",
    "rows_deleted = original_row_count - final.shape[0]\n",
    "\n",
    "print(f\"Silinen satır sayısı: {rows_deleted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "826a4b83-829a-4c23-a957-55cb52099048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final.to_excel('dosya_adi.xlsx') # 👈 Specify the file name you want to export all this data to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae6c4f6-1725-4ca9-a26b-3d5893de3b4e",
   "metadata": {},
   "source": [
    "Copy and paste all keywords in the related_keyword column of this xlsx file into the input field at https://contentgecko.io/free-serp-keyword-clustering. Then select the target country, language and minimum SERP similarity and press the create clusters button. When you enter your e-mail address on the next screen, clustered data will be sent to your e-mail address within two minutes on average. https://prnt.sc/6un7vv3juTlt * 5000 keywords can be clustered at a time. There are no restrictions other than that.\n",
    "\n",
    "Different clustering algorithms can be used here. However, since this tool does the clustering process according to the SERP, we actually act completely according to what Google understands from the relevant search terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a3b7ec-7514-4d3b-8509-22b1a36f8788",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parse a Clustered Keyword File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b65f2f-fc35-4860-a0e2-f7ad12d3e7c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Cluster results will be sent to your e-mail address in xlsx format. (https://prnt.sc/5AfOEJByPHbt) Download this file to your computer and enter the file path in the code block below. This code block will process the xlsx file and extract all keywords belonging to the cluster group in which the keyword you have specified is in. In this way, keywords that are not related to the keyword will be eliminated and you will be able to access the final data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "474377be-5ecf-4d9e-94b7-c3a81c9c582e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Upload the CSV file sent to your e-mail address from contentgecko. 👇\n",
    "df = pd.read_excel('contentgecko-10060-2024-06-17.xlsx') \n",
    "\n",
    "\n",
    "aranan_kelimeler = seed_terms\n",
    "  \n",
    "\n",
    "\n",
    "changed_rows = set()\n",
    "\n",
    "\n",
    "for kelime in aranan_kelimeler:\n",
    "    \n",
    "    matching_rows = df[df['keyword'] == kelime]\n",
    "    \n",
    "    \n",
    "    clusters_to_change = matching_rows['cluster'].unique()\n",
    "    \n",
    "    \n",
    "    for cluster_value in clusters_to_change:\n",
    "        \n",
    "        indices = df.loc[df['cluster'] == cluster_value].index\n",
    "        df.loc[indices, 'cluster'] = kelime\n",
    "        \n",
    "        \n",
    "        changed_rows.update(indices)\n",
    "\n",
    "\n",
    "df_changed = df.loc[sorted(changed_rows)]\n",
    "df_changed = df_changed[df_changed['search_volume'] >= 10] # It deletes those with a search volume of less than 10. You can increase this value if you want.\n",
    "\n",
    "# Enter a file name to save the results in a new CSV file 👇\n",
    "df_changed.to_csv('dosya_adi.csv', index=False)\n",
    "\n",
    "# Created by Anil Burak Karadede (https://www.linkedin.com/in/anilburakkaradede/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
